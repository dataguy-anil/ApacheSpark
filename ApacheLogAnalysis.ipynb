{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fde5d19e290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "sc = SparkContext(\"local\",'ApacheApp')\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "    'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "def parse_apache_time(s):\n",
    "    \"\"\" Convert Apache time format into a Python datetime object\n",
    "    Args:\n",
    "        s (str): date and time in Apache time format\n",
    "    Returns:\n",
    "        datetime: datetime object (ignore timezone for now)\n",
    "    \"\"\"\n",
    "    return datetime.datetime(int(s[7:11]),\n",
    "                             month_map[s[3:6]],\n",
    "                             int(s[0:2]),\n",
    "                             int(s[12:14]),\n",
    "                             int(s[15:17]),\n",
    "                             int(s[18:20]))\n",
    "\n",
    "\n",
    "def parseApacheLogLine(logline):\n",
    "    \"\"\" Parse a line in the Apache Common Log format\n",
    "    Args:\n",
    "        logline (str): a line of text in the Apache Common Log format\n",
    "    Returns:\n",
    "        tuple: either a dictionary containing the parts of the Apache Access Log and 1,\n",
    "               or the original invalid log line and 0\n",
    "    \"\"\"\n",
    "    match = re.search(APACHE_ACCESS_LOG_PATTERN, logline)\n",
    "    if match is None:\n",
    "        return (logline, 0)\n",
    "    size_field = match.group(9)\n",
    "    if size_field == '-':\n",
    "        size = long(0)\n",
    "    else:\n",
    "        size = long(match.group(9))\n",
    "    return (Row(\n",
    "        host          = match.group(1),\n",
    "        client_identd = match.group(2),\n",
    "        user_id       = match.group(3),\n",
    "        date_time     = parse_apache_time(match.group(4)),\n",
    "        method        = match.group(5),\n",
    "        endpoint      = match.group(6),\n",
    "        protocol      = match.group(7),\n",
    "        response_code = int(match.group(8)),\n",
    "        content_size  = size\n",
    "    ), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A regular expression pattern to extract fields from the log line\n",
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\" (\\d{3}) (\\S+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid logline: 895\n",
      "Invalid logline: 198.213.130.253 - - [03/Aug/1995:11:29:02 -0400] \"GET /shuttle/missions/sts-34/mission-sts-34.html\"><IMG images/ssbuv1.gif SRC=\"images/small34p.gif/ HTTP/1.0\" 404 -\n",
      "Invalid logline: ztm-13.dial.xs4all.nl - - [04/Aug/1995:09:34:52 -0400] \"GET / /   HTTP/1.0\" 200 7034\n",
      "Invalid logline: pc32.cis.uoguelph.ca - - [04/Aug/1995:10:57:21 -0400] \"GET / /   HTTP/1.0\" 200 7034\n",
      "Invalid logline: sgate08.st-and.ac.uk - - [04/Aug/1995:17:52:59 -0400] \"GET /htbin/wais.pl?Wake Shield HTTP/1.0\" 200 6858\n",
      "Invalid logline: userp2.snowhill.com - - [05/Aug/1995:14:57:06 -0400] \"GET / \" HTTP/1.0\" 200 7034\n",
      "Invalid logline: ppp-nyc-2-64.ios.com - - [05/Aug/1995:20:45:33 -0400] \"GET /shuttle/missions/sts-69/images/images.html 40,207 89,234 HTTP/1.0\" 200 2443\n",
      "Invalid logline: ppp-nyc-2-64.ios.com - - [05/Aug/1995:20:47:52 -0400] \"GET /shuttle/countdown/tour.html 40,243 89,262 HTTP/1.0\" 200 4347\n",
      "Invalid logline: client-71-162.online.apple.com - - [05/Aug/1995:22:53:19 -0400] \"GET /msfc/astro home.html HTTP/1.0\" 404 -\n",
      "Invalid logline: client-71-162.online.apple.com - - [05/Aug/1995:22:53:47 -0400] \"GET /msfc/astro home.html HTTP/1.0\" 404 -\n",
      "Invalid logline: rt99-9.rotterdam.nl.net - - [06/Aug/1995:11:35:40 -0400] \"GET / /   HTTP/1.0\" 200 7034\n",
      "Invalid logline: client-71-69.online.apple.com - - [06/Aug/1995:12:21:18 -0400] \"GET /msfc/astro home.html HTTP/1.0\" 404 -\n",
      "Invalid logline: spark1.ecf.toronto.edu - - [06/Aug/1995:16:13:52 -0400] \"GET / history/apollo/apollo-13/apollo-13.html HTTP/1.0\" 200 7034\n",
      "Invalid logline: bos49.pi.net - - [06/Aug/1995:16:31:40 -0400] \"GET /htbin/wais.pl?satellite pictures HTTP/1.0\" 200 321\n",
      "Invalid logline: 194.151.8.5 - - [07/Aug/1995:08:48:56 -0400] \"GET / /   HTTP/1.0\" 200 7034\n",
      "Invalid logline: www.db.erau.edu - - [07/Aug/1995:11:19:10 -0400] \"GET /robots.txt HTML/1.0 headers\" 404 -\n",
      "Invalid logline: pc532-03.gsfc.nasa.gov - - [07/Aug/1995:12:40:13 -0400] \"GET /facilities/mila.html>Merritt Island Spaceflight Tracking and Data Network Station (MILA)</a>\" 404 -\n",
      "Invalid logline: ara2.acs.muohio.edu - - [07/Aug/1995:20:40:00 -0400] \"GET /history/apollo/apollo-13/apollo1-.html    apollo-1 HTTP/1.0\" 404 -\n",
      "Invalid logline: ara2.acs.muohio.edu - - [07/Aug/1995:20:41:10 -0400] \"GET /history/apollo/apollo-13/apollo1-.html    apollo-1 HTTP/1.0\" 404 -\n",
      "Invalid logline: ara2.acs.muohio.edu - - [07/Aug/1995:20:41:18 -0400] \"GET /history/apollo/apollo-13/apollo1-.html    apollo-1 HTTP/1.0\" 404 -\n",
      "Invalid logline: hyperweb.mit.edu - - [08/Aug/1995:09:01:06 -0400] \"GET /shuttle/technology/sts-newsref/http://www.ksc.nasa.gov/images/shuttle-patch-logo.gif> Table of\" 404 -\n",
      "Read 1569898 lines, successfully parsed 1569003 lines, failed to parse 895 lines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "logFile = '/data/spark/project/NASA_access_log_Aug95.gz'\n",
    "\n",
    "def parseLogs():\n",
    "    \"\"\" Read and parse log file \"\"\"\n",
    "    parsed_logs = (sc\n",
    "                   .textFile(logFile)\n",
    "                   .map(parseApacheLogLine)\n",
    "                   .cache())\n",
    "\n",
    "    access_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 1)\n",
    "                   .map(lambda s: s[0])\n",
    "                   .cache())\n",
    "\n",
    "    failed_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 0)\n",
    "                   .map(lambda s: s[0]))\n",
    "    failed_logs_count = failed_logs.count()\n",
    "    if failed_logs_count > 0:\n",
    "        print 'Number of invalid logline: %d' % failed_logs.count()\n",
    "        for line in failed_logs.take(20):\n",
    "            print 'Invalid logline: %s' % line\n",
    "\n",
    "    print 'Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (parsed_logs.count(), access_logs.count(), failed_logs.count())\n",
    "    return parsed_logs, access_logs, failed_logs\n",
    "\n",
    "\n",
    "parsed_logs, access_logs, failed_logs = parseLogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on the above data, please answer following questions:\n",
    "# Q1: Write spark code( using RDD) to find out top 10 requested URLs along with count of number of times they have been requested (This information will help company to find out most popular pages and how frequently they are accessed)\n",
    "# Sample output:\n",
    "# URL                                                              Count\n",
    "# shuttle/missions/sts-71/mission-sts-71.html     549\n",
    "# shuttle/resources/orbiters/enterprise.html        145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten URLs/Endpoints requested: [(u'/images/NASA-logosmall.gif', 97384), (u'/images/KSC-logosmall.gif', 75332), (u'/images/MOSAIC-logosmall.gif', 67441), (u'/images/USA-logosmall.gif', 67061), (u'/images/WORLD-logosmall.gif', 66437), (u'/images/ksclogo-medium.gif', 62771), (u'/ksc.html', 43683), (u'/history/apollo/images/apollo-logo1.gif', 37824), (u'/images/launch-logo.gif', 35135), (u'/', 30327), (u'/images/ksclogosmall.gif', 27808), (u'/shuttle/missions/sts-69/mission-sts-69.html', 24606), (u'/shuttle/countdown/', 24458), (u'/shuttle/missions/sts-69/count69.gif', 24381), (u'/shuttle/missions/sts-69/sts-69-patch-small.gif', 23404)]\n"
     ]
    }
   ],
   "source": [
    "# Top Endpoints\n",
    "endpointCounts = (access_logs\n",
    "                  .map(lambda log: (log.endpoint, 1))\n",
    "                  .reduceByKey(lambda a, b : a + b))\n",
    "\n",
    "topEndpoints = endpointCounts.takeOrdered(15, lambda s: -1 * s[1])\n",
    "print 'Top Ten URLs/Endpoints requested: %s' % topEndpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q2: Write spark code to find out top 5 hosts / IP making the request along with count (This information will help company to find out locations where website is popular or to figure out potential DDoS attacks)\n",
    "# Sample output: \n",
    "# URL                    Count\n",
    "# 192.168.78.24     219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'edams.ksc.nasa.gov', 6530),\n",
       " (u'piweba4y.prodigy.com', 4846),\n",
       " (u'163.206.89.4', 4791),\n",
       " (u'piweba5y.prodigy.com', 4607),\n",
       " (u'piweba3y.prodigy.com', 4416),\n",
       " (u'www-d1.proxy.aol.com', 3889),\n",
       " (u'www-b2.proxy.aol.com', 3534),\n",
       " (u'www-b3.proxy.aol.com', 3463),\n",
       " (u'www-c5.proxy.aol.com', 3423),\n",
       " (u'www-b5.proxy.aol.com', 3411),\n",
       " (u'www-c2.proxy.aol.com', 3407),\n",
       " (u'www-d2.proxy.aol.com', 3404),\n",
       " (u'www-a2.proxy.aol.com', 3337),\n",
       " (u'news.ti.com', 3298),\n",
       " (u'www-d3.proxy.aol.com', 3296),\n",
       " (u'www-b4.proxy.aol.com', 3293),\n",
       " (u'www-c3.proxy.aol.com', 3272),\n",
       " (u'www-d4.proxy.aol.com', 3234),\n",
       " (u'www-c1.proxy.aol.com', 3177),\n",
       " (u'www-c4.proxy.aol.com', 3134)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostCountPairTuple = access_logs.map(lambda log: (log.host, 1))\n",
    "hostSum = hostCountPairTuple.reduceByKey(lambda a, b : a + b)\n",
    "hostSum.takeOrdered(20, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Above list shows the host/ip address from where highest number of URL requests originated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q3: Write spark code to find out top 5 time frame for high traffic (which day of the week or hour of the day receives peak traffic, this information will help company to manage resources for handling peak traffic load)\n",
    "# Sample Output:\n",
    "# |        host     |req_cnt|\n",
    "# |  edams.gov |   6530|\n",
    "\n",
    "# Q4: Write spark code to find out 5 time frames of least traffic (which day of the week or hour of the day receives least traffic, this information will help company to do production deployment in that time frame so that less number of users will be affected if some thing goes wrong during deployment)\n",
    "# Sample Output:\n",
    "# |     timeFrame    |req_cnt|\n",
    "# |31/Nov/1995:11|   5000|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thursday', 303979),\n",
       " ('Tuesday', 278666),\n",
       " ('Wednesday', 255452),\n",
       " ('Friday', 234356),\n",
       " ('Monday', 228242),\n",
       " ('Sunday', 134663),\n",
       " ('Saturday', 133645)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import calendar\n",
    "access_logs.map(lambda log: (calendar.day_name[log.date_time.weekday()], 1)).reduceByKey(lambda a, b : a + b).takeOrdered(7, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Above Code run indicates, Thursday is the week of the day in general with high traffic.\n",
    "# Above Code run indicates, Saturday is the week of the day in general with least traffic. Sunday can also be counted with least traffic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 109419),\n",
       " (12, 105132),\n",
       " (13, 104502),\n",
       " (14, 101320),\n",
       " (16, 99484),\n",
       " (11, 95312),\n",
       " (10, 88222),\n",
       " (17, 80800),\n",
       " (9, 78654),\n",
       " (18, 66773),\n",
       " (8, 65411),\n",
       " (22, 60622),\n",
       " (20, 59895),\n",
       " (19, 59285),\n",
       " (21, 57951),\n",
       " (23, 54539),\n",
       " (0, 47805),\n",
       " (7, 47349),\n",
       " (1, 38527),\n",
       " (2, 32506),\n",
       " (6, 31257),\n",
       " (3, 29962),\n",
       " (5, 27555),\n",
       " (4, 26721)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_logs.map(lambda log: (log.date_time.hour, 1)).reduceByKey(lambda a, b : a + b).takeOrdered(24, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As per Python date time notation, hour '15' represents the hour beginning at 3pm.\n",
    "# So, we can interpret the time duration 4am-6am is the time frame with least traffic.\n",
    "# Also, note that the hour beginning 3pm is the time frame with high traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There is catch though. Note that the time frame analysis based on weekday and hour above done seperately and now lets try to combine both weekday and hour factors to assess the traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TrafficRDD = access_logs.map(lambda log: ((calendar.day_name[log.date_time.weekday()], log.date_time.hour), 1)).reduceByKey(lambda a, b : a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Thursday', 15), 23379),\n",
       " (('Thursday', 12), 23032),\n",
       " (('Tuesday', 13), 21115),\n",
       " (('Tuesday', 12), 20908),\n",
       " (('Thursday', 13), 20422),\n",
       " (('Thursday', 14), 20411),\n",
       " (('Thursday', 11), 19693),\n",
       " (('Tuesday', 15), 19269),\n",
       " (('Thursday', 16), 19245),\n",
       " (('Tuesday', 11), 19212)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrafficRDD.takeOrdered(10, lambda s: -1 * s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the above analysis, top 5 time widows with highest traffic can be observed at the following hours:\n",
    "# Thursday beginning 3pm\n",
    "# Thursday beginning 12pm\n",
    "# Tuesday beginning 1pm\n",
    "# Tuesday beginning 12pm\n",
    "# Thursday beginning 1pm\n",
    "# Thursday beginning 2pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Sunday', 6), 2437),\n",
       " (('Saturday', 5), 2579),\n",
       " (('Sunday', 5), 2734),\n",
       " (('Saturday', 6), 2748),\n",
       " (('Sunday', 4), 2807),\n",
       " (('Sunday', 3), 2828),\n",
       " (('Saturday', 4), 2838),\n",
       " (('Sunday', 8), 2957),\n",
       " (('Saturday', 7), 3122),\n",
       " (('Sunday', 2), 3282)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrafficRDD.takeOrdered(10, lambda s: s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the above analysis, top 5 time widows with least traffic can be observed at the following hours:\n",
    "# Sunday beginning 6am\n",
    "# Saturday beginning 5am\n",
    "# Sunday beginning 5am\n",
    "# Saturday beginning 6am\n",
    "# Sunday beginning 4am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q5: Write spark code to find out unique HTTP codes returned by the server along with count (this information is helpful for devops team to find out how many requests are failing so that appropriate action can be taken to fix the issue)\n",
    "# Sample output:\n",
    "# HTTP code            Count\n",
    "# 200 - 15400 \n",
    "# 404    324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 response codes\n",
      "Response Code Counts: [(200, 1398207), (302, 26437), (304, 134138), (403, 171), (404, 10020), (500, 3), (501, 27)]\n"
     ]
    }
   ],
   "source": [
    "responseCodeToCount = (access_logs\n",
    "                       .map(lambda log: (log.response_code, 1))\n",
    "                       .reduceByKey(lambda a, b : a + b)\n",
    "                       .cache())\n",
    "responseCodeToCountList = responseCodeToCount.takeOrdered(100)\n",
    "print 'Found %d response codes' % len(responseCodeToCountList)\n",
    "print 'Response Code Counts: %s' % responseCodeToCountList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
